{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install openimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iu4U6EvmGIQZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from openimages.download import download_dataset\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RegaiI-wT71k"
      },
      "source": [
        "Defining transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "COSLcUrpGQ_2"
      },
      "outputs": [],
      "source": [
        "transformTrain = transforms.Compose([\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.Resize((128, 128)),\n",
        "  transforms.Pad(2),\n",
        "  transforms.RandomCrop((128,128)),\n",
        "  transforms.RandomRotation(10),\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "transformTest = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(), ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60AYDwUxT-Ib"
      },
      "source": [
        "Loading datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toQoLa9uT7Gj",
        "outputId": "3cbc039b-0750-47cd-c715-a644b02c6425"
      },
      "outputs": [],
      "source": [
        "data_dir = \"data\"\n",
        "number_for_samples = 500\n",
        "classes = [\"Orange\", \"Umbrella\", \"Strawberry\"]\n",
        "\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "    download_dataset(data_dir, classes, limit=number_for_samples)\n",
        "else:\n",
        "  print(\"Dataset already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWIOJbC_ZRAv"
      },
      "source": [
        "We create a file object with all of the files loaded according to class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "L7x-_E_5ZQcZ"
      },
      "outputs": [],
      "source": [
        "images_dir = \"./data\"\n",
        "files = { c : [] for c in classes}\n",
        "for c in classes:\n",
        "  files[c] = glob.glob(images_dir + \"/{}/images/*.jpg\".format(c.lower()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXxeGH0QVBYI"
      },
      "source": [
        "Slicing files array to train files and test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ggURma3sb5dH"
      },
      "outputs": [],
      "source": [
        "trainFiles = {c : [] for c in classes}\n",
        "testFiles = {c : [] for c in classes}\n",
        "for c in classes:\n",
        "    trainFiles[c] = files[c][:int(len(files[c]) * 0.8)]\n",
        "    testFiles[c] = files[c][-int(len(files[c]) * 0.2):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BniNshbcVDrR"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, files, transform):\n",
        "        self.files = files\n",
        "        self.transform = transform\n",
        "\n",
        "        # get each class lengths\n",
        "        self.length = {c : [] for c in classes}\n",
        "        for c in classes:\n",
        "          self.length[c] = len(files[c])\n",
        "\n",
        "        self.all_files = [item for sublist in files.values() for item in sublist]\n",
        "\n",
        "        # set labels\n",
        "        self.labels = np.zeros(len(self.all_files))\n",
        "        self.labels[self.length[classes[0]]:self.length[classes[0]]+self.length[classes[1]]] = 1\n",
        "        self.labels[self.length[classes[0]]+self.length[classes[1]]:] = 2\n",
        "\n",
        "        # shuffle data\n",
        "        self.order =  [x for x in np.random.permutation(len(self.labels))]\n",
        "        self.all_files = [self.all_files[x] for x in self.order]\n",
        "        self.labels = [self.labels[x] for x in self.order]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.all_files))\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        file = self.all_files[i]\n",
        "\n",
        "        image = Image.open(file).convert('RGB')\n",
        "        img = self.transform(image)\n",
        "\n",
        "        label = self.labels[i]\n",
        "        return (img, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpam2MgwilGK"
      },
      "source": [
        "Creating test and train datasets, dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OdOeTcyiikyd"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(trainFiles, transformTrain)\n",
        "test_dataset = CustomDataset(testFiles, transformTest)\n",
        "\n",
        "num_workers = 2\n",
        "batch_size = 8\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "j_zs1VdDoftI",
        "outputId": "d76927f0-1c92-4ad5-df3c-3f38b04b5d95"
      },
      "outputs": [],
      "source": [
        "img = train_dataset[0][0].numpy()\n",
        "plt.imshow(img.transpose(1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rZAzY2b0syZ",
        "outputId": "ac4df05f-9bdb-49cb-cb3e-6a95a90efb32"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, classes_count):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(classes_count, 16, 5)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(32 * 29 * 29, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, classes_count)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 29 * 29) \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "num_classes = 3\n",
        "net = CNN(num_classes)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyVBCH915v7A"
      },
      "source": [
        "Defining helper methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NbxXnPJLSzdF"
      },
      "outputs": [],
      "source": [
        "def get_acc(outputs, labels):\n",
        "    with torch.no_grad():\n",
        "        outputLabels = torch.argmax(outputs, 1) # gets the highest prediction for each batch element\n",
        "        return torch.sum((labels == outputLabels).float())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XZAACHE_THBg"
      },
      "outputs": [],
      "source": [
        "def set_to_device(data, device):\n",
        "    return (d.to(device) for d in data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "krONgwJX6tvS"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda'\n",
        "\n",
        "N_train = len(train_dataset)\n",
        "N_test = len(test_dataset)\n",
        "\n",
        "\n",
        "def train(network, n_epochs, lr):\n",
        "  network.to(DEVICE)\n",
        "\n",
        "  optimizer = torch.optim.Adam(network.parameters(), lr=lr)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  for epoch in range(0, n_epochs):\n",
        "\n",
        "      train_loss = 0.0\n",
        "      train_acc = 0.0\n",
        "      test_loss = 0.0\n",
        "      test_acc = 0.0\n",
        "\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "          images, labels = set_to_device(data, DEVICE)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = net(images)\n",
        "\n",
        "          loss = criterion(outputs, labels.long())\n",
        "\n",
        "          train_loss += loss.item() * images.size(0)\n",
        "          train_acc += get_acc(outputs, labels)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      for data in test_loader:\n",
        "          with torch.no_grad():\n",
        "            images, labels = set_to_device(data, DEVICE)\n",
        "            outputs = net(images)\n",
        "\n",
        "            loss = criterion(outputs, labels.long())\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            test_acc += get_acc(outputs, labels)\n",
        "\n",
        "\n",
        "      print('Epoch: {} | Train Loss: {:.6f} | Train Acc: {:.3f} | Test Loss: {:.6f} | Test Acc: {:.3f}'.format(\n",
        "            epoch,\n",
        "            train_loss / N_train,\n",
        "            train_acc / N_train,\n",
        "            test_loss / N_test,\n",
        "            test_acc / N_test,\n",
        "            ))\n",
        "\n",
        "  torch.cuda.synchronize()\n",
        "\n",
        "  print('Finished Training')\n",
        "  torch.save(net.state_dict(), 'trained_model_parameters.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# This is where all the changes were implemented"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdRK5i2y8EIT",
        "outputId": "048ef149-d5c2-473b-c9d7-781388a8db6f"
      },
      "outputs": [],
      "source": [
        "# smaller learning rate\n",
        "train(net, 30, 1e-5)\n",
        "train(net, 20, 1e-6)\n",
        "train(net, 10, 1e-7)\n",
        "\n",
        "torch.save(net.state_dict(), 'trained_model_parameters.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA5I_QLDm8cB"
      },
      "source": [
        "# statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "k8PN8m4Qhsfw"
      },
      "outputs": [],
      "source": [
        "def printConfusionMatrix(conf_matrix, classes):\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Reds\", cbar=False, xticklabels=classes, yticklabels=classes)\n",
        "  plt.xlabel(\"Predicted Labels\")\n",
        "  plt.ylabel(\"True Labels\")\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgmqUVpDm8LS",
        "outputId": "c2a2b4f0-bc66-4ba2-9084-d3537e154337"
      },
      "outputs": [],
      "source": [
        "true_values = []\n",
        "predicted_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = set_to_device(data, DEVICE)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        true_values.extend(labels.cpu().numpy())\n",
        "        predicted_values.extend(predicted.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(true_values, predicted_values)\n",
        "print(f\"Accuracy: {accuracy:.5f}\")\n",
        "\n",
        "recall = recall_score(true_values, predicted_values, average='weighted')\n",
        "print(f\"Recall: {recall:.5f}\")\n",
        "\n",
        "precision = precision_score(true_values, predicted_values, average='weighted')\n",
        "print(f\"Precision: {precision:.5f}\")\n",
        "\n",
        "f1 = f1_score(true_values, predicted_values, average='weighted')\n",
        "print(f\"F1 Score: {f1:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "UwKVDC2Lh-ZW",
        "outputId": "6a1f3400-5475-4b09-c7d6-18570cb8d8b7"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(true_values, predicted_values)\n",
        "printConfusionMatrix(conf_matrix, classes)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
