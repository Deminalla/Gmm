{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install openimages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iu4U6EvmGIQZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from openimages.download import download_dataset\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RegaiI-wT71k"
      },
      "source": [
        "Defining transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "COSLcUrpGQ_2"
      },
      "outputs": [],
      "source": [
        "transformTrain = transforms.Compose([\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.Resize((128, 128)),\n",
        "  transforms.Pad(2),\n",
        "  transforms.RandomCrop((128,128)),\n",
        "  transforms.RandomRotation(10),\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "transformTest = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(), ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60AYDwUxT-Ib"
      },
      "source": [
        "Loading datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toQoLa9uT7Gj",
        "outputId": "3cbc039b-0750-47cd-c715-a644b02c6425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already exists\n"
          ]
        }
      ],
      "source": [
        "data_dir = \"data\"\n",
        "number_for_samples = 500\n",
        "classes = [\"Orange\", \"Umbrella\", \"Strawberry\"]\n",
        "\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "    download_dataset(data_dir, classes, limit=number_for_samples)\n",
        "else:\n",
        "  print(\"Dataset already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWIOJbC_ZRAv"
      },
      "source": [
        "We create a file object with all of the files loaded according to class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "L7x-_E_5ZQcZ"
      },
      "outputs": [],
      "source": [
        "images_dir = \"./data\"\n",
        "files = { c : [] for c in classes}\n",
        "for c in classes:\n",
        "  files[c] = glob.glob(images_dir + \"/{}/images/*.jpg\".format(c.lower()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXxeGH0QVBYI"
      },
      "source": [
        "Slicing files array to train files and test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ggURma3sb5dH"
      },
      "outputs": [],
      "source": [
        "trainFiles = {c : [] for c in classes}\n",
        "testFiles = {c : [] for c in classes}\n",
        "for c in classes:\n",
        "    trainFiles[c] = files[c][:int(len(files[c]) * 0.8)]\n",
        "    testFiles[c] = files[c][-int(len(files[c]) * 0.2):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BniNshbcVDrR"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, files, transform):\n",
        "        self.files = files\n",
        "        self.transform = transform\n",
        "\n",
        "        # get each class lengths\n",
        "        self.length = {c : [] for c in classes}\n",
        "        for c in classes:\n",
        "          self.length[c] = len(files[c])\n",
        "\n",
        "        self.all_files = [item for sublist in files.values() for item in sublist] # flattens list\n",
        "\n",
        "        # set labels\n",
        "        self.labels = np.zeros(len(self.all_files))\n",
        "        self.labels[self.length[classes[0]]:self.length[classes[0]]+self.length[classes[1]]] = 1\n",
        "        self.labels[self.length[classes[0]]+self.length[classes[1]]:] = 2\n",
        "\n",
        "        # shuffle data\n",
        "        self.order =  [x for x in np.random.permutation(len(self.labels))]\n",
        "        self.all_files = [self.all_files[x] for x in self.order]\n",
        "        self.labels = [self.labels[x] for x in self.order]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.all_files))\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        file = self.all_files[i]\n",
        "\n",
        "        image = Image.open(file).convert('RGB')\n",
        "        img = self.transform(image)\n",
        "\n",
        "        label = self.labels[i]\n",
        "        return (img, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpam2MgwilGK"
      },
      "source": [
        "Creating test and train datasets, dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OdOeTcyiikyd"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(trainFiles, transformTrain)\n",
        "test_dataset = CustomDataset(testFiles, transformTest)\n",
        "\n",
        "num_workers = 2\n",
        "batch_size = 8\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "j_zs1VdDoftI",
        "outputId": "d76927f0-1c92-4ad5-df3c-3f38b04b5d95"
      },
      "outputs": [],
      "source": [
        "img = train_dataset[0][0].numpy()\n",
        "plt.imshow(img.transpose(1,2,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rZAzY2b0syZ",
        "outputId": "ac4df05f-9bdb-49cb-cb3e-6a95a90efb32"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, classes_count):\n",
        "        super(CNN, self).__init__()\n",
        "        # classes_count: Number of input channels, 3 for RGB (1R, 1G, 1B), 1 for grayscale\n",
        "        \n",
        "        # 16: Number of output channels, feature maps for images (128 x128)\n",
        "        # The output channels are unique filters that are applied to the input image. Each filter detects different features in the image. \n",
        "        # The more output channels you have, the more features the network can potentially learn and recognize\n",
        "        \n",
        "        # 5: Size of the convolution kernel, 5x5\n",
        "        # Smaller kernels (e.g., 3x3) are often used because they have fewer parameters and are computationally more efficient\n",
        "        # Larger kernels can capture more spatial hierarchies in the input data but at the expense of increased computational cost\n",
        "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
        "        # now the input channel is 16, which is the number of output channels from the previous layer\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "\n",
        "\t    # Max pooling over a (2, 2) window, stride is 2, because of maxpool dimensions\n",
        "        # Max pooling is a downsampling operation that reduces the dimensions (width & height) of the input while retaining the most important information\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # fully connected layers\n",
        "        # 32 * 29 * 29: The size of the input to the fully connected layer is the size of the output from convs and maxpools\n",
        "        # we get dimensions 29x29 after conv1, maxpool, conv2, maxpool\n",
        "        # after conv1: 124 = 128-5+1\n",
        "        # after maxpool: 62 = (124-2) /2 +1\n",
        "        # after conv2: 58 = 62-5+1\n",
        "        # after maxpool: 29 = (58-2) /2 +1\n",
        "        # 32 i think might just be the output from conv2\n",
        "        # 120: number of neurons in the fully connected layer (this is the output)\n",
        "        self.fc1 = nn.Linear(32 * 29 * 29, 120)\n",
        "        # 120: Number of input features\n",
        "        # 84: Number of neurons in the fully connected layer\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        # The purpose is to perform the final classification and produce the output prediction probabilities for each class\n",
        "        # the nr of outputs, neurons the final layer will have is the same as the categories we have (orange,....)\n",
        "        self.fc3 = nn.Linear(84, classes_count)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x))) # relu for non-linearity\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 29 * 29) # Flatten the output of conv2 to 1 dimensional vector to be fed into the fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "num_classes = 3\n",
        "myNet = CNN(num_classes)\n",
        "print(myNet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyVBCH915v7A"
      },
      "source": [
        "Defining helper methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XZAACHE_THBg"
      },
      "outputs": [],
      "source": [
        "def set_to_device(data, device):\n",
        "    return (d.to(device) for d in data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NbxXnPJLSzdF"
      },
      "outputs": [],
      "source": [
        "def get_acc(outputs, labels):\n",
        "    with torch.no_grad():\n",
        "        outputLabels = torch.argmax(outputs, 1)\n",
        "        return torch.sum((labels == outputLabels).float())\n",
        "    \n",
        "# outputs returns a list of predictions for an image to belong to a class, so an array of 3 elements\n",
        "# outputsLabels picks the index of the highest prediction (which class it belongs to)\n",
        "# outputs contains 8 arrays, because we load data in batches of 8 (I set that above)\n",
        "\n",
        "# outputs  tensor([[-0.8575,  1.3114, -1.0110],\n",
        "#         [-4.8837,  0.3225,  2.8092],\n",
        "#         [-0.8008,  0.6337, -0.3348],\n",
        "#         [ 1.7059,  1.5647, -3.2893],\n",
        "#         [-1.0364,  2.8903, -2.9380],\n",
        "#         [-1.0849,  2.4910, -2.3542],\n",
        "#         [-2.2653,  4.8638, -4.3033],\n",
        "#         [ 2.0741,  2.0949, -4.8366]], device='cuda:0')\n",
        "# outputLabels tensor([1, 2, 1, 0, 1, 1, 1, 1], device='cuda:0')\n",
        "\n",
        "# softmax pavercia raw values i predictions/probability, tai del accuracy calculations, nereik nei softmax nei sigmoid\n",
        "# mes nenaudojam softmax per CNN forward() nes nn.CrossEntropyLoss() acceptina raw values\n",
        "# ir internally applyina softmax, o mes gaunam accuracy po CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "krONgwJX6tvS"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda'\n",
        "\n",
        "N_train = len(train_dataset)\n",
        "N_test = len(test_dataset)\n",
        "\n",
        "\n",
        "def train(network, n_epochs, lr):\n",
        "  network.to(DEVICE)\n",
        "\n",
        "  optimizer = torch.optim.Adam(network.parameters(), lr=lr) # Initializes the optimizer to update model parameters during training\n",
        "  criterion = nn.CrossEntropyLoss() # for computing loss\n",
        "\n",
        "  for epoch in range(0, n_epochs):\n",
        "\n",
        "      train_loss = 0.0\n",
        "      train_acc = 0.0\n",
        "      test_loss = 0.0\n",
        "      test_acc = 0.0\n",
        "\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "          images, labels = set_to_device(data, DEVICE)\n",
        "\n",
        "          optimizer.zero_grad() # clear gradients from previous cycle\n",
        "          outputs = myNet(images) # When you pass an argument to myNet, you are essentially passing an input tensor through the neural network to get the output predictions\n",
        "\n",
        "          loss = criterion(outputs, labels.long()) # calculates loss\n",
        "\n",
        "          train_loss += loss.item() * images.size(0) # images.size(0) returns batch size\n",
        "          train_acc += get_acc(outputs, labels)\n",
        "\n",
        "          loss.backward() # calculates the gradients for each parameter in the model. \n",
        "          # These gradients will be used by the optimizer to update the model weights during the optimization step.\n",
        "          optimizer.step() # updates the model parameters using the computed gradients\n",
        "\n",
        "      for data in test_loader:\n",
        "          with torch.no_grad():\n",
        "            images, labels = set_to_device(data, DEVICE)\n",
        "            outputs = myNet(images)\n",
        "\n",
        "            loss = criterion(outputs, labels.long())\n",
        "\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            test_acc += get_acc(outputs, labels)\n",
        "\n",
        "            # In testing (or validation), you don't need to compute gradients or update the model parameters. \n",
        "\n",
        "\n",
        "      print('Epoch: {} | Train Loss: {:.6f} | Train Acc: {:.3f} | Test Loss: {:.6f} | Test Acc: {:.3f}'.format(\n",
        "            epoch,\n",
        "            train_loss / N_train,\n",
        "            train_acc / N_train,\n",
        "            test_loss / N_test,\n",
        "            test_acc / N_test,\n",
        "            ))\n",
        "\n",
        "  torch.cuda.synchronize() # ensures that all the operations on the CUDA device have been completed before moving on to the next operations on the CPU\n",
        "\n",
        "  print('Finished Training')\n",
        "  torch.save(myNet.state_dict(), 'trained_model_parameters.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdRK5i2y8EIT",
        "outputId": "048ef149-d5c2-473b-c9d7-781388a8db6f"
      },
      "outputs": [],
      "source": [
        "train(myNet, 30, 1e-3)\n",
        "train(myNet, 20, 1e-4)\n",
        "train(myNet, 10, 1e-5)\n",
        "\n",
        "torch.save(myNet.state_dict(), 'trained_model_parameters.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA5I_QLDm8cB"
      },
      "source": [
        "# statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgmqUVpDm8LS",
        "outputId": "c2a2b4f0-bc66-4ba2-9084-d3537e154337"
      },
      "outputs": [],
      "source": [
        "true_values = []\n",
        "predicted_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = set_to_device(data, DEVICE)\n",
        "        outputs = myNet(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        true_values.extend(labels.cpu().numpy())\n",
        "        predicted_values.extend(predicted.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(true_values, predicted_values)\n",
        "print(f\"Accuracy: {accuracy:.5f}\")\n",
        "\n",
        "recall = recall_score(true_values, predicted_values, average='weighted')\n",
        "print(f\"Recall: {recall:.5f}\")\n",
        "\n",
        "precision = precision_score(true_values, predicted_values, average='weighted')\n",
        "print(f\"Precision: {precision:.5f}\")\n",
        "\n",
        "f1 = f1_score(true_values, predicted_values, average='weighted')\n",
        "print(f\"F1 Score: {f1:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "k8PN8m4Qhsfw"
      },
      "outputs": [],
      "source": [
        "def printConfusionMatrix(conf_matrix, classes):\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Reds\", cbar=False, xticklabels=classes, yticklabels=classes)\n",
        "  plt.xlabel(\"Predicted Labels\")\n",
        "  plt.ylabel(\"True Labels\")\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "UwKVDC2Lh-ZW",
        "outputId": "6a1f3400-5475-4b09-c7d6-18570cb8d8b7"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(true_values, predicted_values)\n",
        "printConfusionMatrix(conf_matrix, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flask import Flask, render_template, request\n",
        "app = Flask(__name__, template_folder=\"./\")\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "  return render_template(\"index.html\")\n",
        "\n",
        "@app.route('/calculate_scores', methods=['POST'])\n",
        "def calculate_scores():\n",
        "    if 'image' not in request.files:\n",
        "        return \"No image uploaded\", 400\n",
        "\n",
        "    image_file = request.files['image']\n",
        "    image = Image.open(image_file.stream)\n",
        "\n",
        "    input_tensor = transformTest(image).unsqueeze(0) # prepares it as a tensor suitable for the neural network model\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      predictions = myNet(input_tensor)\n",
        "      _, predicted_class = predictions.max(1) # finds the index of the highest score, which corresponds to the predicted class.\n",
        "      predicted_label = classes[predicted_class]\n",
        "\n",
        "    return \"Predicted class: \" + predicted_label\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
